{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "from torch import optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './source-data/'\n",
    "sub_path = 'detailed/'   # change this when it is necessary\n",
    "spilits_path = 'cv/profileID/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(root_path+sub_path+'profiles.csv.xz')\n",
    "data_target = pd.read_csv(root_path+sub_path+'outputs.csv.xz').iloc[:,-2:].values\n",
    "data_splits = pd.read_csv(root_path+sub_path+spilits_path+'folds.csv').iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = data['sequenceID'].unique()\n",
    "name_list.sort()\n",
    "data_dym_storage = []\n",
    "for name in name_list:\n",
    "    data_dym_storage.append(data[data['sequenceID'] == name]['signal'].values)\n",
    "data_dym_storage = np.array(data_dym_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splits_do(fold_id):\n",
    "    tfmarker = (data_splits == fold_id)\n",
    "    data_train = data_dym_storage[~tfmarker]\n",
    "    data_trtar = data_target[~tfmarker]\n",
    "    data_test = data_dym_storage[tfmarker]\n",
    "    data_tstar = data_target[tfmarker]\n",
    "    return data_train, data_trtar, data_test, data_tstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_trtar, data_test, data_tstar = data_splits_do(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareHingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquareHingeLoss,self).__init__()\n",
    "    \n",
    "    def ifelse(self, condition, a, b):\n",
    "        crit = (condition >= 0).squeeze(1)\n",
    "        copy_con = condition.clone()\n",
    "        copy_con[crit] = condition[crit] ** 2\n",
    "        copy_con[~crit] = b\n",
    "        return copy_con\n",
    "\n",
    "    def phi(self, in_phi):\n",
    "        return self.ifelse(in_phi, in_phi**2, 0) \n",
    "       \n",
    "    def forward(self, x, target_y):\n",
    "#         print(torch.mean(self.phi(-x + target_y[:,:,0] + 1) + self.phi(x - target_y[:,:,1] + 1)))\n",
    "        return torch.mean(self.phi(- x + target_y[:,:,0] + 1) + self.phi(x - target_y[:,:,1] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one based on the AdaptiveMax/Avg method built in torch\n",
    "\n",
    "class SpatialPyramidPooling(nn.Module):\n",
    "    \"\"\"Generate fixed length representation regardless of image dimensions\n",
    "    Based on the paper \"Spatial Pyramid Pooling in Deep Convolutional Networks\n",
    "    for Visual Recognition\" (https://arxiv.org/pdf/1406.4729.pdf)\n",
    "    :param [int] num_pools: Number of pools to split each input feature map into.\n",
    "        Each element must be a perfect square in order to equally divide the\n",
    "        pools across the feature map. Default corresponds to the original\n",
    "        paper's implementation\n",
    "    :param str mode: Specifies the type of pooling, either max or avg\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pools=[1, 4, 16], mode='max'):\n",
    "        super(SpatialPyramidPooling, self).__init__()\n",
    "        self.name = 'SpatialPyramidPooling'\n",
    "        if mode == 'max':\n",
    "            pool_func = nn.AdaptiveMaxPool1d\n",
    "        elif mode == 'avg':\n",
    "            pool_func = nn.AdaptiveAvgPool1d\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown pooling mode '{mode}', expected 'max' or 'avg'\")\n",
    "        self.pools = []\n",
    "        for p in num_pools:\n",
    "            self.pools.append(pool_func(p))\n",
    "\n",
    "    def forward(self, feature_maps):\n",
    "        \"\"\"Pool feature maps at different bin levels and concatenate\n",
    "        :param torch.tensor feature_maps: Arbitrarily shaped spatial and\n",
    "            channel dimensions extracted from any generic convolutional\n",
    "            architecture. Shape ``(N, C, W)``\n",
    "        :return torch.tensor pooled: Concatenation of all pools with shape\n",
    "            ``(N, C, sum(num_pools))``\n",
    "        \"\"\"\n",
    "        assert feature_maps.dim() == 3, 'Expected 3D input of (N, C, W)'\n",
    "        batch_size = feature_maps.size(0)\n",
    "        channels = feature_maps.size(1)\n",
    "        pooled = []\n",
    "        for p in self.pools:\n",
    "            pooled.append(p(feature_maps).view(batch_size, channels, -1))\n",
    "        return torch.cat(pooled, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet, self).__init__()\n",
    "        self.spp = SpatialPyramidPooling()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 5, 3), # 8 x 332\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(8, 16, 3, 2, 1), # 16 x 166\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 32, 3, 2, 1), # 32 x 83\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 32, 3, 2, 1), # 32 x 42\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(32*21, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.layer1(x)\n",
    "        x = self.spp(x)\n",
    "        x = x.reshape(x.size(0),-1)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = convNet().to(device)\n",
    "criterion = SquareHingeLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 507])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(data_train[0]).view(1,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "num_epoches = 3000\n",
    "train_loss_record = np.zeros(num_epoches)\n",
    "train_acc_record = np.zeros(num_epoches)\n",
    "test_loss_record = np.zeros(num_epoches)\n",
    "test_acc_record = np.zeros(num_epoches)\n",
    "for epoch in range(num_epoches):\n",
    "    loss_value, iter_num, print_loss = 0, 0, 0\n",
    "    acc = 0\n",
    "    for i, (data, target) in enumerate(zip(data_train, data_trtar)):\n",
    "        e += 1\n",
    "        iter_num += 1\n",
    "        data = torch.from_numpy(data).view(1, 1, -1)\n",
    "        data = Variable(data).to(device)\n",
    "        target = torch.from_numpy(target).view(-1, 1)\n",
    "        target = Variable(target).to(device)\n",
    "        inputs = inputs.type(torch.DoubleTensor).to(device)\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, targets.float())\n",
    "        optimier.zero_grad()\n",
    "        loss.backward()\n",
    "        optimier.step()\n",
    "        \n",
    "        print_loss += loss.cpu().data.numpy()\n",
    "        acc += accuarcy(out.cpu().data, targets.cpu().data.float()).data.numpy()\n",
    "    \n",
    "    test_in = Variable(valdataset.tensors[0]).to(device)\n",
    "    test_in = test_in.type(torch.DoubleTensor).to(device)\n",
    "    test_out = model(test_in)\n",
    "    test_loss = criterion(test_out, Variable(valdataset.tensors[1].cuda()).float())\n",
    "    test_loss = test_loss.cpu().data.numpy()\n",
    "    test_acc = accuarcy(test_out.cpu().data, valdataset.tensors[1].float()).data.numpy()\n",
    "        \n",
    "    print('-'* 120)\n",
    "    print('Epoch [{:-03d}/{}]  |  Train Loss:  {:.3f}  |  Test Loss:  {:.3f}  |  Test Accuarcy:  {:.3f}  |  Train Accuracy:  {:.3f}'\n",
    "          .format(epoch+1, num_epoches, print_loss/iter_num, test_loss, test_acc, acc/iter_num))\n",
    "    train_loss_record[epoch] = print_loss/iter_num\n",
    "    test_loss_record[epoch] = test_loss\n",
    "    train_acc_record[epoch] = acc/iter_num\n",
    "    test_acc_record[epoch] = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
