{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement directly\n",
    "\n",
    "def spatial_pyramid_pool_1d(self,previous_conv, num_sample, previous_conv_size, out_pool_size):\n",
    "    '''\n",
    "    previous_conv: a tensor vector of previous convolution layer\n",
    "    num_sample: an int number of image in the batch\n",
    "    previous_conv_size: an int vector [height, width] of the matrix features size of previous convolution layer\n",
    "    out_pool_size: a int vector of expected output size of max pooling layer\n",
    "    \n",
    "    returns: a tensor vector with shape [1 x n] is the concentration of multi-level pooling\n",
    "    '''    \n",
    "    # print(previous_conv.size())\n",
    "    for i in range(len(out_pool_size)):\n",
    "        # print(previous_conv_size)\n",
    "        w_wid = torch.ceil(previous_conv_size[1] / out_pool_size[i])\n",
    "        \n",
    "        w_pad = (w_wid*out_pool_size[i] - previous_conv_size[1] + 1)/2\n",
    "        maxpool = nn.MaxPool1d(w_wid, stride=w_wid, padding=w_pad)\n",
    "        x = maxpool(previous_conv)\n",
    "        if(i == 0):\n",
    "            spp = x.view(num_sample,-1)\n",
    "            # print(\"spp size:\",spp.size())\n",
    "        else:\n",
    "            # print(\"size:\",spp.size())\n",
    "            spp = torch.cat((spp,x.view(num_sample,-1)), 1)\n",
    "    return spp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one based on the AdaptiveMax/Avg method built in torch\n",
    "\n",
    "class SpatialPyramidPooling(nn.Module):\n",
    "    \"\"\"Generate fixed length representation regardless of image dimensions\n",
    "    Based on the paper \"Spatial Pyramid Pooling in Deep Convolutional Networks\n",
    "    for Visual Recognition\" (https://arxiv.org/pdf/1406.4729.pdf)\n",
    "    :param [int] num_pools: Number of pools to split each input feature map into.\n",
    "        Each element must be a perfect square in order to equally divide the\n",
    "        pools across the feature map. Default corresponds to the original\n",
    "        paper's implementation\n",
    "    :param str mode: Specifies the type of pooling, either max or avg\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pools=[1, 4, 16], mode='max'):\n",
    "        super(SpatialPyramidPooling, self).__init__()\n",
    "        self.name = 'SpatialPyramidPooling'\n",
    "        if mode == 'max':\n",
    "            pool_func = nn.AdaptiveMaxPool1d\n",
    "        elif mode == 'avg':\n",
    "            pool_func = nn.AdaptiveAvgPool1d\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown pooling mode '{mode}', expected 'max' or 'avg'\")\n",
    "        self.pools = []\n",
    "        for p in num_pools:\n",
    "            side_length = math.sqrt(p)\n",
    "            if not side_length.is_integer():\n",
    "                raise ValueError(f'Bin size {p} is not a perfect square')\n",
    "            self.pools.append(pool_func(int(side_length)))\n",
    "\n",
    "    def forward(self, feature_maps):\n",
    "        \"\"\"Pool feature maps at different bin levels and concatenate\n",
    "        :param torch.tensor feature_maps: Arbitrarily shaped spatial and\n",
    "            channel dimensions extracted from any generic convolutional\n",
    "            architecture. Shape ``(N, C, H, W)``\n",
    "        :return torch.tensor pooled: Concatenation of all pools with shape\n",
    "            ``(N, C, sum(num_pools))``\n",
    "        \"\"\"\n",
    "        assert feature_maps.dim() == 3, 'Expected 3D input of (N, C, W)'\n",
    "        batch_size = feature_maps.size(0)\n",
    "        channels = feature_maps.size(1)\n",
    "        pooled = []\n",
    "        for p in self.pools:\n",
    "            pooled.append(p(feature_maps).view(batch_size, channels, -1))\n",
    "        return torch.cat(pooled, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
