{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    df = df.iloc[:,1:] \n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data-processed/detailed/inputs.csv.xz')\n",
    "data_wk = data.copy()\n",
    "data_wk = data_wk.replace([np.inf, -np.inf], np.nan)\n",
    "data_wky = data_wk.dropna(axis=1)\n",
    "outy = pd.read_csv('./data-processed/detailed/outputs.csv')\n",
    "cvv = pd.read_csv('./data-processed/detailed/folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wky = normalize(data_wky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sepration(in_data, out, cvv, val_id):\n",
    "    \"\"\"\n",
    "    convert the df to dataset and seperate between\n",
    "    train and validation set\n",
    "    \"\"\"\n",
    "    trainset = torch.from_numpy(in_data[cvv['fold'] != val_id].values)\n",
    "    traintarget = torch.from_numpy(out[cvv['fold'] != val_id].iloc[:,1:].values)\n",
    "    valset = torch.from_numpy(in_data[cvv['fold'] == val_id].values)\n",
    "    valtarget = torch.from_numpy(out[cvv['fold'] == val_id].iloc[:,1:].values)\n",
    "    return trainset, valset, traintarget, valtarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_set = 1\n",
    "trainset, valset, traintarget, valtarget = data_sepration(data_wky, outy, cvv, i_set)\n",
    "traindataset = TensorDataset(trainset.unsqueeze(1), traintarget.unsqueeze(1))\n",
    "valdataset = TensorDataset(valset.unsqueeze(1), valtarget.unsqueeze(1))\n",
    "trainLoader = DataLoader(traindataset, shuffle=True, batch_size=10000)\n",
    "valLoader = DataLoader(valdataset, shuffle=True, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuarcy(pred, true):\n",
    "    true = true.squeeze(1)\n",
    "    pred = pred.reshape(-1)\n",
    "    count = torch.sum((pred > true[:,0]) & (pred < true[:,1]))\n",
    "#     print(pred)\n",
    "#     print(true[:,0])\n",
    "#     print(true[:,1])\n",
    "#     print(100*count/pred.size(0))\n",
    "    return 100.0*count/pred.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareHingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquareHingeLoss,self).__init__()\n",
    "    \n",
    "    def ifelse(self, condition, a, b):\n",
    "        crit = (condition >= 0).squeeze(1)\n",
    "        copy_con = condition.clone()\n",
    "        copy_con[crit] = condition[crit] ** 2\n",
    "        copy_con[~crit] = b\n",
    "        return copy_con\n",
    "\n",
    "    def phi(self, in_phi):\n",
    "        return self.ifelse(in_phi, in_phi**2, 0) \n",
    "       \n",
    "    def forward(self, x, target_y):\n",
    "#         print(torch.mean(self.phi(-x + target_y[:,:,0] + 1) + self.phi(x - target_y[:,:,1] + 1)))\n",
    "        return torch.mean(self.phi(- x + target_y[:,:,0] + 1) + self.phi(x - target_y[:,:,1] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(256, 1024),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.layer1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convNet().to(device)\n",
    "criterion = SquareHingeLoss()\n",
    "optimier = optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [001/3000]  |  Train Loss:  0.511  |  Test Loss:  0.311  |  Test Accuarcy:  93.813  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [002/3000]  |  Train Loss:  0.496  |  Test Loss:  0.299  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.602\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [003/3000]  |  Train Loss:  0.487  |  Test Loss:  0.292  |  Test Accuarcy:  93.645  |  Train Accuracy:  89.049\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [004/3000]  |  Train Loss:  0.484  |  Test Loss:  0.289  |  Test Accuarcy:  93.645  |  Train Accuracy:  89.400\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [005/3000]  |  Train Loss:  0.486  |  Test Loss:  0.287  |  Test Accuarcy:  93.311  |  Train Accuracy:  89.112\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [006/3000]  |  Train Loss:  0.488  |  Test Loss:  0.287  |  Test Accuarcy:  93.144  |  Train Accuracy:  89.144\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [007/3000]  |  Train Loss:  0.489  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  89.176\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [008/3000]  |  Train Loss:  0.489  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  89.049\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [009/3000]  |  Train Loss:  0.488  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  88.889\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [010/3000]  |  Train Loss:  0.486  |  Test Loss:  0.287  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [011/3000]  |  Train Loss:  0.484  |  Test Loss:  0.288  |  Test Accuarcy:  93.813  |  Train Accuracy:  88.889\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [012/3000]  |  Train Loss:  0.483  |  Test Loss:  0.290  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.985\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [013/3000]  |  Train Loss:  0.482  |  Test Loss:  0.291  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.985\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [014/3000]  |  Train Loss:  0.482  |  Test Loss:  0.293  |  Test Accuarcy:  93.478  |  Train Accuracy:  89.049\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [015/3000]  |  Train Loss:  0.483  |  Test Loss:  0.294  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.793\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [016/3000]  |  Train Loss:  0.483  |  Test Loss:  0.295  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [017/3000]  |  Train Loss:  0.484  |  Test Loss:  0.295  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.602\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [018/3000]  |  Train Loss:  0.484  |  Test Loss:  0.294  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.506\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [019/3000]  |  Train Loss:  0.483  |  Test Loss:  0.293  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.570\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [020/3000]  |  Train Loss:  0.483  |  Test Loss:  0.291  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.602\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [021/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [022/3000]  |  Train Loss:  0.482  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.570\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [023/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.570\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [024/3000]  |  Train Loss:  0.482  |  Test Loss:  0.287  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.570\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [025/3000]  |  Train Loss:  0.482  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  88.538\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [026/3000]  |  Train Loss:  0.482  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  88.506\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [027/3000]  |  Train Loss:  0.482  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  88.538\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [028/3000]  |  Train Loss:  0.482  |  Test Loss:  0.286  |  Test Accuarcy:  93.144  |  Train Accuracy:  88.538\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [029/3000]  |  Train Loss:  0.482  |  Test Loss:  0.287  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.506\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [030/3000]  |  Train Loss:  0.482  |  Test Loss:  0.287  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.506\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [031/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.506\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [032/3000]  |  Train Loss:  0.482  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.474\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [033/3000]  |  Train Loss:  0.482  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.538\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [034/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.538\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [035/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [036/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [037/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.645  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [038/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [039/3000]  |  Train Loss:  0.482  |  Test Loss:  0.290  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [040/3000]  |  Train Loss:  0.482  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.602\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [041/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [042/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [043/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [044/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [045/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [046/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [047/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [048/3000]  |  Train Loss:  0.482  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [049/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [050/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [051/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [052/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [053/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [054/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [055/3000]  |  Train Loss:  0.482  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [056/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [057/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [058/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [059/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [060/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [061/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [062/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [063/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.478  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [064/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.761\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [065/3000]  |  Train Loss:  0.481  |  Test Loss:  0.288  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [066/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [067/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [068/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [069/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.729\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [070/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [071/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [072/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [073/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [074/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [075/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [076/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [077/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [078/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [079/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [080/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [081/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [082/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [083/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [084/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [085/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [086/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [087/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [088/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [089/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [090/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [091/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [092/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [093/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [094/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [095/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [096/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [097/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [098/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.697\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [099/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [100/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [101/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [102/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [103/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [104/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [105/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [106/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [107/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [108/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [109/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [110/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [111/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [112/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [113/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [114/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [115/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [116/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [117/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [118/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [119/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [120/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [121/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [122/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [123/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [124/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [125/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [126/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [127/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [128/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [129/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [130/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [131/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [132/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [133/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [134/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [135/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [136/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [137/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [138/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [139/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [140/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [141/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [142/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [143/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [144/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [145/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [146/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [147/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [148/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [149/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [150/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [151/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [152/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [153/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [154/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [155/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [156/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [157/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [158/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [159/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [160/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [161/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [162/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [163/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [164/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [165/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [166/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [167/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [168/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [169/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [170/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [171/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [172/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [173/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [174/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [175/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [176/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [177/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [178/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [179/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [180/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [181/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [182/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [183/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [184/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [185/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [186/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [187/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [188/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [189/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [190/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [191/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [192/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [193/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [194/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [195/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [196/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [197/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [198/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [199/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [200/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [201/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [202/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [203/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [204/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [205/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [206/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [207/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [208/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [209/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [210/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [211/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [212/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [213/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [214/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [215/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [216/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [217/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [218/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [219/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [220/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [221/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [222/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [223/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [224/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [225/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [226/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [227/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [228/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [229/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [230/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [231/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [232/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [233/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [234/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [235/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [236/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [237/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [238/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [239/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [240/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [241/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [242/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [243/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [244/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [245/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [246/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [247/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [248/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [249/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [250/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [251/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [252/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [253/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [254/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [255/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [256/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [257/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [258/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [259/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [260/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [261/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [262/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [263/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [264/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [265/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [266/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [267/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [268/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [269/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [270/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [271/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [272/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [273/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [274/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [275/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [276/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [277/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [278/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [279/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [280/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [281/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [282/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [283/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [284/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [285/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [286/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [287/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [288/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [289/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [290/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [291/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [292/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [293/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [294/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [295/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [296/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [297/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [298/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [299/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [300/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [301/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [302/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [303/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [304/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [305/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [306/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [307/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [308/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [309/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [310/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [311/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [312/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [313/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [314/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [315/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [316/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [317/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [318/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [319/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [320/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [321/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [322/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [323/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [324/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [325/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [326/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [327/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [328/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [329/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [330/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [331/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [332/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [333/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [334/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [335/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [336/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [337/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [338/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [339/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [340/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [341/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [342/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [343/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [344/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.665\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [345/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [346/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [347/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [348/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [349/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [350/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [351/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [352/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [353/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [354/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [355/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [356/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [357/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [358/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [359/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [360/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [361/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [362/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [363/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [364/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [365/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [366/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch [367/3000]  |  Train Loss:  0.481  |  Test Loss:  0.289  |  Test Accuarcy:  93.311  |  Train Accuracy:  88.633\n",
      "------------------------------------------------------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "e = 0\n",
    "num_epoches = 3000\n",
    "train_loss_record = np.zeros(num_epoches)\n",
    "train_acc_record = np.zeros(num_epoches)\n",
    "test_loss_record = np.zeros(num_epoches)\n",
    "test_acc_record = np.zeros(num_epoches)\n",
    "for epoch in range(num_epoches):\n",
    "    loss_value, iter_num, print_loss = 0, 0, 0\n",
    "    acc = 0\n",
    "    for data in trainLoader:\n",
    "        e += 1\n",
    "        iter_num += 1\n",
    "        inputs, targets = data\n",
    "        inputs = Variable(inputs).to(device)\n",
    "        targets = Variable(targets).to(device)\n",
    "        inputs = inputs.type(torch.DoubleTensor).to(device)\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, targets.float())\n",
    "        optimier.zero_grad()\n",
    "        loss.backward()\n",
    "        optimier.step()\n",
    "        \n",
    "        print_loss += loss.cpu().data.numpy()\n",
    "        acc += accuarcy(out.cpu().data, targets.cpu().data.float()).data.numpy()\n",
    "    \n",
    "    test_in = Variable(valdataset.tensors[0]).to(device)\n",
    "    test_in = test_in.type(torch.DoubleTensor).to(device)\n",
    "    test_out = model(test_in)\n",
    "    test_loss = criterion(test_out, Variable(valdataset.tensors[1].cuda()).float())\n",
    "    test_loss = test_loss.cpu().data.numpy()\n",
    "    test_acc = accuarcy(test_out.cpu().data, valdataset.tensors[1].float()).data.numpy()\n",
    "        \n",
    "    print('-'* 120)\n",
    "    print('Epoch [{:-03d}/{}]  |  Train Loss:  {:.3f}  |  Test Loss:  {:.3f}  |  Test Accuarcy:  {:.3f}  |  Train Accuracy:  {:.3f}'\n",
    "          .format(epoch+1, num_epoches, print_loss/iter_num, test_loss, test_acc, acc/iter_num))\n",
    "    train_loss_record[epoch] = print_loss/iter_num\n",
    "    test_loss_record[epoch] = test_loss\n",
    "    train_acc_record[epoch] = acc/iter_num\n",
    "    test_acc_record[epoch] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc_record)\n",
    "plt.plot(train_acc_record)\n",
    "plt.plot(train_acc_record)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
